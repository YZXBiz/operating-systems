18 Paging: Introduction It is sometimessaidthattheoperatingsystemtakesoneoftwoapproaches when solving most any space-management problem. The first approach is to chop things up into variable-sized pieces, as we saw with segmentation in virtual memory. Unfortunately, this solution has inherent difficulties. In particular, when dividing a space into different-size chunks, the space itself can become fragmented, and thus allocation becomes more challenging over time. Thus, it may be worth considering the second approach: to chop up space into fixed-sized pieces. In virtual memory, we call this idea paging, andit goesbacktoanearlyandimportantsystem,theAtlas[KE+62, L78]. Instead of splitting up a process’s address space into some number of variable-sized logical segments (e.g., code, heap, stack), we divide it into f ixed-sized units, eachofwhichwecallapage. Correspondingly,weview physical memory as anarrayof fixed-sized slots called page frames; each of these frames can contain a single virtual-memory page. Our challenge: THE CRUX: HOWTOVIRTUALIZE MEMORY WITH PAGES How can we virtualize memory with pages, so as to avoid the problems of segmentation? What are the basic techniques? How do we make those techniques work well, with minimal space and time overheads? 18.1 A Simple Example And Overview To help make this approach more clear, let’s illustrate it with a simple example. Figure18.1(page2)presentsanexampleofatinyaddressspace, only 64 bytes total in size, with four 16-byte pages (virtual pages 0, 1, 2, and 3). Real address spaces are much bigger, of course, commonly 32 bits and thus 4-GB of address space, or even 64 bits1; in the book, we’ll often use tiny examples to make them easier to digest. 1A 64-bit address space is hard to imagine, it is so amazingly large. An analogy might help: if you think of a 32-bit address space as the size of a tennis court, a 64-bit address space is about the size of Europe(!). 12 PAGING: INTRODUCTION 0 16 32 48 64 (page 0 of the address space) (page 1) (page 2) (page 3) Figure 18.1: A Simple 64-byte Address Space Physical memory, as shown in Figure 18.2, also consists of a number of fixed-sized slots, in this case eight page frames (making for a 128-byte physical memory, also ridiculously small). As you can see in the diagram, the pages of the virtual address space have been placed at different locations throughout physical memory; the diagram also shows the OS using some of physical memory for itself. Paging, as we will see, has a number of advantages over our previous approaches. Probably the most important improvement will be flexibility: with a fully-developed paging approach, the system will be able to support the abstraction of an address space effectively, regardless of how a process uses the address space; we won’t, for example, make assumptions about the direction the heap and stack grow and how they are used. 0 16 32 48 64 80 reserved for OS (unused) page 3 of AS page 0 of AS (unused) page 2 of AS 96 112 128 (unused) page 1 of AS page frame 0 of physical memory page frame 1 page frame 2 page frame 3 page frame 4 page frame 5 page frame 6 page frame 7 Figure 18.2: A 64-Byte Address Space In A 128-Byte Physical Memory OPERATING SYSTEMS WWW.OSTEP.ORG [VERSION 1.10]PAGING: INTRODUCTION 3 Anotheradvantageisthesimplicityoffree-spacemanagementthatpaging affords. For example, when the OS wishes to place our tiny 64-byte address space into our eight-page physical memory, it simply finds four free pages; perhaps the OS keeps a free list of all free pages for this, and just grabs the first four free pages off of this list. In the example, the OS has placed virtual page 0 of the address space (AS) in physical frame 3, virtual page 1 of the AS in physical frame 7, page 2 in frame 5, and page 3 in frame 2. Page frames 1, 4, and 6 are currently free. To record where each virtual page of the address space is placed in physical memory, the operating system usually keeps a per-process data structure known as a page table. The major role of the page table is to store address translations for each of the virtual pages of the address space, thus letting us know where in physical memory each page resides. For our simple example (Figure 18.2, page 2), the page table would thus have the following four entries: (Virtual Page 0 → Physical Frame 3), (VP 1 →PF7),(VP2→PF5),and(VP3→PF2). It is important to remember that this page table is a per-process data structure (most page table structures we discuss are per-process structures; an exception we’ll touch on is the inverted page table). If another process were to run in our example above, the OS would have to manage a different page table for it, as its virtual pages obviously map to different physical pages (modulo any sharing going on). Now, we know enough to perform an address-translation example. Let’s imagine the process with that tiny address space (64 bytes) is performing a memory access: movl <virtual address>, %eax Specifically, let’s pay attention to the explicit load of the data from address <virtual address>intotheregister eax (and thus ignore the instruction fetch that must have happened prior). To translate this virtual address that the process generated, we have to first split it into two components: the virtual page number (VPN), and the offset within the page. For this example, because the virtual address space of theprocessis 64bytes, weneed6bitstotalforourvirtualaddress (26 = 64). Thus, our virtual address can be conceptualized as follows: Va5 Va4 Va3 Va2 Va1 Va0 In this diagram, Va5 is the highest-order bit of the virtual address, and Va0 the lowest-order bit. Because we know the page size (16 bytes), we can further divide the virtual address as follows: VPN offset Va5 Va4 Va3 Va2 Va1 Va0 ©2008–23, ARPACI-DUSSEAU THREE EASY PIECES4 PAGING: INTRODUCTION The page size is 16 bytes in a 64-byte address space; thus we need to be able to select 4 pages, and the top 2 bits of the address do just that. Thus, we have a2-bit virtual page number (VPN). The remaining bits tell us which byte of the page we are interested in, 4 bits in this case; we call this the offset. When a process generates a virtual address, the OS and hardware must combine to translate it into a meaningful physical address. For example, let us assume the load above was to virtual address 21: movl 21, %eax Turning “21” into binary form, we get “010101”, and thus we can examine this virtual address and see how it breaks down into a virtual page number (VPN) and offset: VPN offset 0 1 0 1 0 1 Thus, the virtual address “21” is on the 5th (“0101”th) byte of virtual page “01” (or 1). With our virtual page number, we can now index our pagetable andfindwhichphysicalframevirtualpage1resideswithin. In the page table above the physical frame number (PFN) (also sometimes called the physical page number or PPN) is 7 (binary 111). Thus, we can translate this virtual address by replacing the VPN withthePFNandthen issue the load to physical memory (Figure 18.3). VPN offset Virtual Address 0 1 Address Translation 0 Physical Address 1 1 1 0 1 0 1 0 1 1 PFN offset Figure 18.3: The Address Translation Process OPERATING SYSTEMS WWW.OSTEP.ORG [VERSION 1.10]5 PAGING: INTRODUCTION 0 16 32 48 64 80 96 112 128 page table: 3 7 5 2 (unused) page 3 of AS page 0 of AS (unused) page 2 of AS (unused) page 1 of AS page frame 0 of physical memory page frame 1 page frame 2 page frame 3 page frame 4 page frame 5 page frame 6 page frame 7 Figure 18.4: Example: Page Table in Kernel Physical Memory Note the offset stays the same (i.e., it is not translated), because the offset just tells us which byte within the page we want. Our final physical address is 1110101 (117 in decimal), and is exactly where we want our load to fetch data from (Figure 18.2, page 2). With this basic overview in mind, we can now ask (and hopefully, answer) a few basic questions you may have about paging. For example, where are these page tables stored? What are the typical contents of the page table, and how big are the tables? Does paging make the system (too) slow? These and other beguiling questions are answered, at least in part, in the text below. Read on! 18.2 Where Are Page Tables Stored? Page tables can get terribly large, much bigger than the small segment table or base/bounds pair we have discussed previously. For example, imagine a typical 32-bit address space, with 4KB pages. This virtual address splits into a 20-bit VPN and 12-bit offset (recall that 10 bits would be needed for a 1KB page size, and just add two more to get to 4KB). A20-bit VPN implies that there are 220 translations that the OS would have to manage for each process (that’s roughly a million); assuming we need 4 bytes per page table entry (PTE) to hold the physical translation plus any other useful stuff, we get an immense 4MB of memory needed for each page table! That is pretty large. Now imagine there are 100 processes running: this means the OS would need 400MB of memory just for all those address translations! Even in the modern era, where ©2008–23, ARPACI-DUSSEAU THREE EASY PIECES6 PAGING: INTRODUCTION ASIDE: DATA STRUCTURE — THE PAGE TABLE One of the most important data structures in the memory management subsystem of a modern OS is the page table. In general, a page table stores virtual-to-physical address translations, thus letting the system know where each page of an address space actually resides in physical memory. Because each address space requires such translations, in general there is one page table per process in the system. The exact structure of the page table is either determined by the hardware (older systems) or can be more flexibly managed by the OS (modern systems). machines have gigabytes of memory, it seems a little crazy to use a large chunk of it just for translations, no? And we won’t even think about how big such a page table would be for a 64-bit address space; that would be too gruesome and perhaps scare you off entirely. Becausepagetablesaresobig, wedon’tkeepanyspecialon-chiphardwareintheMMUtostorethepagetableofthecurrently-runningprocess. Instead, we store the page table for each process in memory somewhere. Let’s assume for now that the page tables live in physical memory that the OSmanages; later we’ll see that much of OS memory itself can be virtualized, and thus page tables can be stored in OS virtual memory (and even swapped to disk), but that is too confusing right now, so we’ll ignore it. In Figure 18.4 (page 5) is a picture of a page table in OS memory; see the tiny set of translations in there? 18.3 What’s Actually In The Page Table? Let’s talk a little about page table organization. The page table is just a data structure that is used to map virtual addresses (or really, virtual page numbers) to physical addresses (physical frame numbers). Thus, any data structure could work. The simplest form is called a linear page table, which is just an array. The OS indexes the array by the virtual page number (VPN), and looks up the page-table entry (PTE) at that index in order to find the desired physical frame number (PFN). For now, we will assume this simple linear structure; in later chapters, we will make use of moreadvanceddatastructures to help solve some problems with paging. As for the contents of each PTE, we have a number of different bits in there worth understanding at some level. A valid bit is common to indicate whether the particular translation is valid; for example, when a program starts running, it will have code and heap at one end of its address space, andthestackattheother. Alltheunusedspacein-between will be marked invalid, and if the process tries to access such memory, it will generate a trap to the OS which will likely terminate the process. Thus, the valid bit is crucial for supporting a sparse address space; by simply marking all the unused pages in the address space invalid, we removetheneedtoallocate physical frames for those pages andthussave a great deal of memory. OPERATING SYSTEMS WWW.OSTEP.ORG [VERSION 1.10]PAGING: INTRODUCTION 7 31 12 11 9876543210 PFN G PAT D A PCD PWT U/S R/W P Figure18.5:Anx86PageTableEntry(PTE) Wealsomighthaveprotectionbits,indicatingwhetherthepagecould bereadfrom,writtento,orexecutedfrom.Again,accessingapageina waynotallowedbythesebitswillgenerateatraptotheOS. Thereareacoupleofotherbitsthatareimportantbutwewon’ttalk aboutmuchfornow.Apresentbitindicateswhetherthispageisinphysicalmemoryorondisk(i.e., ithasbeenswappedout).Wewillunderstandthismachineryfurtherwhenwestudyhowtoswappartsof the addressspacetodisktosupportaddressspacesthatarelargerthanphysicalmemory; swappingallows theOStofreeupphysicalmemoryby movingrarely-usedpagestodisk.Adirtybitisalsocommon,indicating whetherthepagehasbeenmodifiedsinceitwasbroughtintomemory. Areferencebit(a.k.a.accessedbit)issometimesusedtotrackwhether apagehasbeenaccessed,andisuseful indeterminingwhichpagesare popularandthusshouldbekeptinmemory;suchknowledgeiscritical duringpagereplacement,atopicwewillstudyingreatdetailinsubsequentchapters. Figure18.5showsanexamplepagetableentryfromthex86architecture[I09]. It containsapresentbit (P); aread/writebit (R/W)which determinesifwritesareallowedtothispage;auser/supervisorbit(U/S) whichdeterminesifuser-modeprocessescanaccessthepage;afewbits (PWT,PCD,PAT,andG)thatdeterminehowhardwarecachingworksfor thesepages;anaccessedbit(A)andadirtybit(D);andfinally, thepage framenumber(PFN)itself. ReadtheIntelArchitectureManuals[I09]formoredetailsonx86pagingsupport. Beforewarned,however; readingmanualssuchasthese, whilequiteinformative(andcertainlynecessaryforthosewhowritecode tousesuchpagetablesintheOS),canbechallengingatfirst.Alittlepatience,andalotofdesire,isrequired. ASIDE:WHYNOVALIDBIT? YoumaynoticethatintheIntelexample,therearenoseparatevalidand presentbits, but rather justapresentbit (P). If thatbit isset (P=1), it means thepage isbothpresentandvalid. Ifnot (P=0), itmeans that thepagemaynotbepresent inmemory(but isvalid), ormaynotbe valid. Anaccess toapagewithP=0will triggeratraptotheOS; the OSmust thenuseadditional structures itkeeps todeterminewhether thepageisvalid(andthusperhapsshouldbeswappedbackin)ornot (andthustheprogramisattemptingtoaccessmemoryillegally). This sortof judiciousnessiscommoninhardware,whichoftenjustprovide theminimalsetoffeaturesuponwhichtheOScanbuildafullservice. ©2008–23,ARPACI-DUSSEAU THREE EASY PIECES8 PAGING: INTRODUCTION 18.4 Paging: Also Too Slow With page tables in memory, we already know that they might be too big. As it turns out, they can slow things down too. For example, take our simple instruction: movl 21, %eax Again, let’s just examine the explicit reference to address 21 and not worryabouttheinstruction fetch. In this example, we’ll assume the hardwareperformsthetranslation for us. To fetch the desired data, the system must first translate the virtual address (21) into the correct physical address (117). Thus, before fetching the data from address 117, the system must first fetch the proper page table entry from the process’s page table, perform the translation, and then load the data from physical memory. To do so, the hardware must know where the page table is for the currently-running process. Let’s assume for now that a single page-table base register contains the physical address of the starting location of the page table. To findthelocation of the desired PTE, the hardware will thus perform the following functions: VPN = (VirtualAddress & VPN_MASK) >> SHIFT PTEAddr = PageTableBaseRegister + (VPN * sizeof(PTE)) In our example, VPN MASK would be set to 0x30 (hex 30, or binary 110000) whichpicksouttheVPNbitsfromthefullvirtualaddress; SHIFT is set to 4 (the number of bits in the offset), such that we move the VPN bits down to form the correct integer virtual page number. For example, with virtual address 21 (010101), and masking turns this value into 010000; the shift turns it into 01, or virtual page 1, as desired. We then use this value as an index into the array of PTEs pointed to by the page table base register. Once this physical address is known, the hardware can fetch the PTE from memory,extract the PFN,andconcatenate it with the offset from the virtual address to form the desired physical address. Specifically, you can think of the PFNbeing left-shifted by SHIFT, and then bitwise OR’d with the offset to form the final address as follows: offset = VirtualAddress & OFFSET_MASK PhysAddr = (PFN << SHIFT) | offset Finally, the hardware can fetch the desired data from memory and put it into register eax. The program has now succeeded at loading a value from memory! To summarize, we now describe the initial protocol for what happens on each memory reference. Figure 18.6 (page 9) shows the approach. For every memory reference (whether an instruction fetch or an explicit load or store), paging requires us to perform one extra memory reference in order to first fetch the translation from the page table. That is a lot of OPERATING SYSTEMS WWW.OSTEP.ORG [VERSION 1.10]PAGING: INTRODUCTION 9 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // Extract the VPN from the virtual address VPN = (VirtualAddress & VPN_MASK) >> SHIFT // Form the address of the page-table entry (PTE) PTEAddr = PTBR + (VPN * sizeof(PTE)) // Fetch the PTE PTE = AccessMemory(PTEAddr) // Check if process can access the page if (PTE.Valid == False) RaiseException(SEGMENTATION_FAULT) else if (CanAccess(PTE.ProtectBits) == False) RaiseException(PROTECTION_FAULT) else // Access OK: form physical address and fetch it offset = VirtualAddress & OFFSET_MASK PhysAddr = (PTE.PFN << PFN_SHIFT) | offset Register = AccessMemory(PhysAddr) Figure 18.6: Accessing Memory With Paging work! Extra memory references are costly, and in this case will likely slow down the process by a factor of two or more. And now you can hopefully see that there are two real problems that we must solve. Without careful design of both hardware and software, page tables will cause the system to run too slowly, as well as take up too much memory. While seemingly a great solution for our memory virtualization needs, these two crucial problems must first be overcome. 18.5 A MemoryTrace Before closing, we now trace through a simple memory access example to demonstrate all of the resulting memory accesses that occur when using paging. The code snippet (in C, in a file called array.c) that we are interested in is as follows: int array[1000]; ... for (i = 0; i < 1000; i++) array[i] = 0; Wecompile array.c and run it with the following commands: prompt> gcc-o array array.c-Wall-O prompt> ./array ©2008–23, ARPACI-DUSSEAU THREE EASY PIECES10 PAGING: INTRODUCTION Of course, to truly understand what memory accesses this code snippet (which simply initializes an array) will make, we’ll have to know (or assume) a few more things. First, we’ll have to disassemble the resulting binary (using objdump on Linux, or otool on a Mac) to see what assembly instructions are used to initialize the array in a loop. Here is the resulting assembly code: 1024 movl $0x0,(%edi,%eax,4) 1028 incl %eax 1032 cmpl $0x03e8,%eax 1036 jne 1024 Thecode,ifyouknowalittlex86, isactuallyquiteeasytounderstand2. The first instruction moves the value zero (shown as $0x0) into the virtual memoryaddressofthelocationofthearray; thisaddressiscomputed by taking the contents of %edi and adding %eax multiplied by four to it. Thus, %edi holds the base address of the array, whereas %eax holds the array index (i); we multiply by four because the array is an array of integers, each of size four bytes. The second instruction increments the array index held in %eax, and the third instruction compares the contents of that register to the hex value 0x03e8, or decimal 1000. If the comparison shows that two values are not yet equal (which is what the jne instruction tests), the fourth instruction jumps back to the top of the loop. Tounderstandwhichmemoryaccessesthisinstructionsequencemakes (at both the virtual and physical levels), we’ll have to assume something about where in virtual memory the code snippet and array are found, as well as the contents and location of the page table. For this example, we assume a virtual address space of size 64KB (unrealistically small). We also assume a page size of 1KB. All we need to know now are the contents of the page table, and its location in physical memory. Let’s assume we have a linear (array-based) page table and that it is located at physical address 1KB (1024). As for its contents, there are just a few virtual pages we need to worry about having mapped for this example. First, there is the virtual page the code lives on. Because the page size is 1KB, virtual address 1024 resides on the second page of the virtual address space (VPN=1, as VPN=0 is the first page). Let’s assume this virtual page maps to physical frame 4 (VPN 1→PFN4). Next, there is the array itself. Its size is 4000 bytes (1000 integers), and we assume that it resides at virtual addresses 40000 through 44000 (not including the last byte). The virtual pages for this decimal range are VPN=39 ... VPN=42. Thus, we need mappings for these pages. Let’s assumethesevirtual-to-physicalmappingsfortheexample: (VPN39→PFN7), (VPN 40 →PFN8),(VPN41→PFN9),(VPN42→PFN10). 2We are cheating a little bit here, assuming each instruction is four bytes in size for simplicity; in actuality, x86 instructions are variable-sized. OPERATING SYSTEMS WWW.OSTEP.ORG [VERSION 1.10]PAGING: INTRODUCTION 11 PageTable[39] PageTable[1] Array (VA) 40100 40050 40000 mov Code (VA) 1124 1074 1024 mov inc cmp jne 0 10 20 30 40 50 Memory Access 1224 1174 1124 1074 1024 7332 7282 7232 4196 4146 4096 Page Table (PA) Array (PA) Code (PA) Figure 18.7: A Virtual (And Physical) Memory Trace We are now ready to trace the memory references of the program. Whenitruns,eachinstructionfetchwillgeneratetwomemoryreferences: onetothepagetabletofindthephysicalframethattheinstructionresides within, and one to the instruction itself to fetch it to the CPU for processing. In addition, there is one explicit memory reference in the form of the mov instruction; this adds another page table access first (to translate the array virtual address to the correct physical one) and then the array access itself. The entire process, for the first five loop iterations, is depicted in Figure 18.7 (page 11). The bottom mostgraphshowstheinstruction memory references on the y-axis in black (with virtual addresses on the left, and the actual physical addresses on the right); the middle graph shows array accesses in dark gray (again with virtual on left and physical on right); finally, the topmost graph shows page table memory accesses in light gray (just physical, as the page table in this example resides in physical memory). The x-axis, for the entire trace, shows memory accesses across the f irst five iterations of the loop; there are 10 memory accesses per loop, which includes four instruction fetches, one explicit update of memory, andfivepagetableaccessestotranslatethosefourfetchesandoneexplicit update. ©2008–23, ARPACI-DUSSEAU THREE EASY PIECES12 PAGING: INTRODUCTION See if you can make sense of the patterns that show up in this visualization. In particular, what will change as the loop continues to run beyond these first five iterations? Which new memory locations will be accessed? Can you figure it out? This hasjust beenthesimplestofexamples(onlyafewlinesofCcode), andyet youmightalreadybeabletosense the complexity of understanding the actual memory behavior of real applications. Don’t worry: it definitely gets worse, because the mechanismsweareabouttointroduceonly complicate this already complex machinery. Sorry3! 18.6 Summary We have introduced the concept of paging as a solution to our challenge of virtualizing memory. Paging has many advantages over previous approaches (such as segmentation). First, it does not lead to external fragmentation, as paging (by design) divides memory into fixed-sized units. Second, it is quite flexible, enabling the sparse use of virtual address spaces. However, implementing paging support without care will lead to a slower machine (with many extra memory accesses to access the page table) as well as memory waste (with memory filled with page tables instead of useful application data). We’ll thus have to think a little harder to come up with a paging system that not only works, but works well. The next two chapters, fortunately, will show us how to do so.