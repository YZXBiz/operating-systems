20 Paging: Smaller Tables We now tackle the second problem that paging introduces: page tables are too big and thus consume too much memory. Let’s start out with a linear page table. As you might recall1, linear page tables get pretty big. Assume again a 32-bit address space (232 bytes), with 4KB (212 byte) pages and a 4-byte page-table entry. An address space thus has roughly one million virtual pages in it (232 212 ); multiply by the page-table entry size and you see that our page table is 4MB in size. Recall also: we usually have one page table for every process in the system! With a hundred active processes (not uncommon on a modern system), we will be allocating hundreds of megabytes of memory just for page tables! As a result, we are in search of some techniques to reduce this heavy burden. There are a lot of them, so let’s get going. But not before our crux: CRUX: HOW TO MAKE PAGE TABLES SMALLER? Simple array-based page tables (usually called linear page tables) are too big, taking up far too much memory on typical systems. How can we make page tables smaller? What are the key ideas? What inefficiencies arise as a result of these new data structures? 20.1 Simple Solution: Bigger Pages We could reduce the size of the page table in one simple way: use bigger pages. Take our 32-bit address space again, but this time assume 16KB pages. We would thus have an 18-bit VPN plus a 14-bit offset. Assuming the same size for each PTE (4 bytes), we now have 218 entries in our linear page table and thus a total size of 1MB per page table, a factor 1Or indeed, you might not; this paging thing is getting out of control, no? That said, alwaysmakesureyouunderstandtheproblemyouaresolvingbeforemovingontothesolution; indeed, if you understand the problem, you can often derive the solution yourself. Here, the problem should be clear: simple linear (array-based) page tables are too big. 12 PAGING:SMALLERTABLES ASIDE:MULTIPLEPAGESIZES Asanaside,donotethatmanyarchitectures(e.g.,MIPS,SPARC,x86-64) nowsupportmultiplepagesizes. Usually, asmall (4KBor8KB)page sizeisused.However, ifa“smart”applicationrequestsit,asinglelarge page(e.g.,ofsize4MB)canbeusedforaspecificportionoftheaddress space,enablingsuchapplicationstoplaceafrequently-used(andlarge) datastructureinsuchaspacewhileconsumingonlyasingleTLBentry. Thistypeof largepageusageiscommonindatabasemanagement systemsandotherhigh-endcommercialapplications. Themainreason formultiplepagesizesisnottosavepagetablespace,however; it isto reducepressureontheTLB,enablingaprogramtoaccessmoreofitsaddressspacewithoutsufferingfromtoomanyTLBmisses. However,as researchershaveshown[N+02],usingmultiplepagesizesmakestheOS virtualmemorymanagernotablymorecomplex, andthus largepages aresometimesmosteasilyusedsimplybyexportinganewinterfaceto applicationstorequestlargepagesdirectly. offourreductioninsizeofthepagetable(notsurprisingly,thereduction exactlymirrorsthefactoroffourincreaseinpagesize). Themajorproblemwiththisapproach,however,isthatbigpageslead towastewithineachpage,aproblemknownasinternalfragmentation (asthewasteisinternaltotheunitofallocation).Applicationsthusend upallocatingpagesbutonlyusinglittlebitsandpiecesofeach,andmemoryquicklyfillsupwiththeseoverly-largepages.Thus,mostsystemsuse relativelysmallpagesizesinthecommoncase:4KB(asinx86)or8KB(as inSPARCv9).Ourproblemwillnotbesolvedsosimply,alas. 20.2HybridApproach:PagingandSegments Wheneveryouhavetworeasonablebutdifferentapproachestosomethinginlife,youshouldalwaysexaminethecombinationofthetwoto seeifyoucanobtainthebestofbothworlds.Wecallsuchacombinationa hybrid.Forexample,whyeatjustchocolateorplainpeanutbutterwhen youcaninsteadcombinethetwoinalovelyhybridknownastheReese’s PeanutButterCup[M28]? Yearsago, thecreatorsofMultics(inparticularJackDennis)chanced uponsuchanideaintheconstructionoftheMulticsvirtualmemorysystem[M07]. Specifically,Dennishadtheideaofcombiningpagingand segmentationinorder toreducethememoryoverheadofpagetables. Wecanseewhythismightworkbyexaminingatypical linearpagetableinmoredetail.Assumewehaveanaddressspaceinwhichtheused portionsoftheheapandstackaresmall. Fortheexample,weuseatiny 16KBaddressspacewith1KBpages(Figure20.1); thepagetableforthis addressspaceisinFigure20.2. OPERATING SYSTEMS [VERSION1.10] WWW.OSTEP.ORGPAGING:SMALLERTABLES 3 code heap stack Virtual Address Space Physical Memory 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 Figure20.1:A16KBAddressSpaceWith1KBPages PFN valid prot present dirty 10 1 r-x 1 0- 0 —--- 0 —--- 0 —-23 1 rw- 1 1- 0 —--- 0 —--- 0 —--- 0 —--- 0 —--- 0 —--- 0 —--- 0 —--- 0 —-28 1 rw- 1 1 4 1 rw- 1 1 Figure20.2:APageTableFor16KBAddressSpace Thisexampleassumes thesinglecodepage (VPN0) ismappedto physicalpage10, thesingleheappage(VPN4)tophysicalpage23,and thetwostackpagesattheotherendoftheaddressspace(VPNs14and ©2008–23,ARPACI-DUSSEAU THREE EASY PIECES4 PAGING: SMALLER TABLES 15) are mapped to physical pages 28 and 4, respectively. As you can see from the picture, most of the page table is unused, full of invalid entries. What a waste! And this is for a tiny 16KB address space. Imagine the page table of a 32-bit address space and all the potential wasted space in there! Actually, don’t imagine such a thing; it’s far too gruesome. Thus, our hybrid approach: instead of having a single page table for the entire address space of the process, why not have one per logical segment? In this example, we might thus have three page tables, one for the code, heap, and stack parts of the address space. Now, remember with segmentation, we had a base register that told us where each segment lived in physical memory, and a bound or limit register that told us the size of said segment. In our hybrid, we still have those structures in the MMU; here, we use the base not to point to the segment itself but rather to hold the physical address of the page table of that segment. The boundsregister is used to indicate the end of the page table (i.e., how many valid pages it has). Let’s do a simple example to clarify. Assume a 32-bit virtual address space with 4KB pages, and an address space split into four segments. We’ll only use three segments for this example: one for code, one for heap, and one for stack. To determine which segment an address refers to, we’ll use the top two bits of the address space. Let’s assume 00 is the unused segment, with 01 for code, 10 for the heap, and 11 for the stack. Thus, a virtual address looks like this: 3 1 3 0 2 9 2 8 2 7 2 6 2 5 2 4 2 3 2 2 2 1 2 0 1 9 1 8 1 7 1 6 1 5 1 4 1 3 1 2 1 1 1 0 0 9 0 8 0 7 0 6 0 5 0 4 0 3 0 2 0 1 0 0 Seg VPN Offset In the hardware, assume that there are thus three base/bounds pairs, one each for code, heap, and stack. When a process is running, the base register for each of these segments contains the physical address of a linear page table for that segment; thus, each process in the system now has three page tables associated with it. On a context switch, these registers must be changed to reflect the location of the page tables of the newlyrunning process. On a TLB miss (assuming a hardware-managed TLB, i.e., where the hardware is responsible for handling TLB misses), the hardware uses the segment bits (SN) to determine which base and bounds pair to use. The hardware then takes the physical address therein and combines it with the VPNas follows to form the address of the page table entry (PTE): SN VPN = (VirtualAddress & SEG_MASK) >> SN_SHIFT = (VirtualAddress & VPN_MASK) >> VPN_SHIFT AddressOfPTE = Base[SN] + (VPN * sizeof(PTE)) This sequence should look familiar; it is virtually identical to what we saw before with linear page tables. The only difference, of course, is the use of one of three segment base registers instead of the single page table base register. OPERATING SYSTEMS WWW.OSTEP.ORG [VERSION 1.10]PAGING: SMALLER TABLES 5 TIP: USE HYBRIDS When you have two good and seemingly opposing ideas, you should alwaysseeifyoucancombinethemintoahybridthatmanagestoachieve the best of both worlds. Hybrid corn species, for example, are known to be more robust than any naturally-occurring species. Of course, not all hybrids are a good idea; see the Zeedonk (or Zonkey), which is a cross of a Zebra and a Donkey. If you don’t believe such a creature exists, look it up, and prepare to be amazed. Thecritical difference in our hybrid schemeisthepresenceofabounds register per segment; each bounds register holds the value of the maximum valid page in the segment. For example, if the code segment is using its first three pages (0, 1, and 2), the code segment page table will only have three entries allocated to it and the bounds register will be set to 3; memoryaccesses beyondtheendofthesegmentwillgenerateanexception and likely lead to the termination of the process. In this manner, our hybrid approach realizes a significant memory savings compared to the linear page table; unallocated pages between the stack and the heap no longer take up space in a page table (just to mark them as not valid). However, as you might notice, this approach is not without problems. First, it still requires us to use segmentation; as we discussed before, segmentation is not quite as flexible as we would like, as it assumes a certain usage pattern of the address space; if we have a large but sparsely-used heap, for example, we can still end up with a lot of page table waste. Second, this hybrid causes external fragmentation to arise again. While most of memory is managed in page-sized units, page tables now can be of arbitrary size (in multiples of PTEs). Thus, finding free space for them in memory is more complicated. For these reasons, people continued to look for better ways to implement smaller page tables. 20.3 Multi-level Page Tables Adifferentapproachdoesn’trelyonsegmentationbutattacksthesame problem: how to get rid of all those invalid regions in the page table instead of keeping them all in memory? Wecallthisapproachamulti-level pagetable, as it turns the linear page table into something like a tree. This approach is so effective that many modern systems employ it (e.g., x86 [BOH10]). We now describe this approach in detail. Thebasic idea behind a multi-level page table is simple. First, chop up the page table into page-sized units; then, if an entire page of page-table entries (PTEs) is invalid, don’t allocate that page of the page table at all. To track whether a page of the page table is valid (and if valid, where it is in memory), use a new structure, called the page directory. The page directory thus either can be used to tell you where a page of the page table is, or that the entire page of the page table contains no valid pages. ©2008–23, ARPACI-DUSSEAU THREE EASY PIECES6 PAGING: SMALLER TABLES Linear Page Table PTBR 201 valid prot PFN 1 rx 12 1 rx 13 0-1 rw 100 0-0-0-0-0-0-0-0-0-0-1 rw 86 1 rw 15 Multi-level Page Table PDBR 200 valid PFN 1 201 00PFN 201 PFN 202 PFN 203 PFN 204 PFN 200 1 204 The Page Directory valid prot PFN 1 rx 12 1 rx 13 0-1 rw 100 PFN 201 [Page 1 of PT: Not Allocated] [Page 2 of PT: Not Allocated] 0-0-1 rw 86 1 rw 15 PFN 204 Figure 20.3: Linear (Left) And Multi-Level (Right) Page Tables Figure 20.3 shows an example. On the left of the figure is the classic linear page table; even though most of the middle regions of the address space are not valid, we still require page-table space allocated for those regions (i.e., the middle two pages of the page table). On the right is a multi-level page table. The page directory marks just two pages of the page table as valid (the first and last); thus, just those two pages of the page table reside in memory. And thus you can see one way to visualize what a multi-level table is doing: it just makes parts of the linear page table disappear (freeing those frames for other uses), and tracks which pages of the page table are allocated with the page directory. The page directory, in a simple two-level table, contains one entry per page of the page table. It consists of a number of page directory entries (PDE). A PDE (minimally) has a valid bit and a page frame number (PFN), similar to a PTE. However, as hinted at above, the meaning of this valid bit is slightly different: if the PDE is valid, it means that at least one of the pages of the page table that the entry points to (via the PFN) is valid, i.e., in at least one PTE on that page pointed to by this PDE, the valid bit in that PTE is set to one. If the PDE is not valid (i.e., equal to zero), the rest of the PDE is not defined. Multi-level pagetables havesomeobviousadvantagesoverapproaches we’ve seen thus far. First, and perhaps most obviously, the multi-level table only allocates page-table space in proportion to the amount of address space you are using; thus it is generally compact and supports sparse address spaces. Second, if carefully constructed, each portion of the page table fits neatly within a page, making it easier to manage memory; the OS can simply grab the next free page when it needs to allocate or grow a page OPERATING SYSTEMS WWW.OSTEP.ORG [VERSION 1.10]PAGING: SMALLER TABLES 7 TIP: UNDERSTAND TIME-SPACE TRADE-OFFS When building a data structure, one should always consider time-space trade-offs in its construction. Usually, if you wish to make access to a particular data structure faster, you will have to pay a space-usage penalty for the structure. table. Contrast this to a simple (non-paged) linear page table2, which is just an array of PTEs indexed by VPN; with such a structure, the entire linear page table must reside contiguously in physical memory. For a large page table (say 4MB), finding such a large chunk of unused contiguous free physical memory can bequiteachallenge. With a multi-level structure, we add alevel ofindirection through use of thepagedirectory, whichpointstopiecesofthepagetable; thatindirectionallowsustoplace page-table pages wherever we would like in physical memory. It should be noted that there is a cost to multi-level tables; on a TLB miss, two loads from memory will be required to get the right translation information from the page table (one for the page directory, and one for the PTE itself), in contrast to just one load with a linear page table. Thus, the multi-level table is a small example of a time-space trade-off. We wanted smaller tables (and got them), but not for free; although in the common case (TLB hit), performance is obviously identical, a TLB miss suffers from a higher cost with this smaller table. Another obvious negative is complexity. Whether it is the hardware or OShandling the page-table lookup (on a TLB miss), doing so is undoubtedly more involved than a simple linear page-table lookup. Often we are willing to increase complexity in order to improve performance or reduce overheads; in the case of a multi-level table, we make page-table lookups more complicated in order to save valuable memory. ADetailed Multi-Level Example To understand the idea behind multi-level page tables better, let’s do an example. Imagine a small address space of size 16KB, with 64-byte pages. Thus, we have a 14-bit virtual address space, with 8 bits for the VPN and 6 bits for the offset. A linear page table would have 28 (256) entries, even if only a small portion of the address space is in use. Figure 20.4 (page 8) presents one example of such an address space. In this example, virtual pages 0 and 1 are for code, virtual pages 4 and 5 for the heap, and virtual pages 254 and 255 for the stack; the rest of the pages of the address space are unused. To build a two-level page table for this address space, we start with our full linear page table and break it up into page-sized units. Recall our full table (in this example) has 256 entries; assume each PTE is 4 bytes 2We are making some assumptions here, i.e., that all page tables reside in their entirety in physical memory (i.e., they are not swapped to disk); we’ll soon relax this assumption. ©2008–23, ARPACI-DUSSEAU THREE EASY PIECES8 PAGING: SMALLER TABLES 0000 0000 0000 0001 0000 0010 0000 0011 0000 0100 0000 0101 0000 0110 0000 0111 ................ 1111 1100 1111 1101 1111 1110 1111 1111 code code (free) (free) heap heap (free) (free) ... all free ... (free) (free) stack stack Figure 20.4: A 16KB Address Space With 64-byte Pages in size. Thus, our page table is 1KB (256 × 4 bytes) in size. Given that wehave64-byte pages, the 1KB page table can be divided into 16 64-byte pages; each page can hold 16 PTEs. What we need to understand now is how to take a VPN and use it to index first into the pagedirectory andthenintothepageofthepagetable. Remember that each is an array of entries; thus, all we need to figure out is how to construct the index for each from pieces of the VPN. Let’s first index into the page directory. Our page table in this example is small: 256entries, spread across16pages. Thepagedirectoryneedsone entry per page of the page table; thus, it has 16 entries. As a result, we need four bits of the VPN to index into the directory; we use the top four bits of the VPN, as follows: VPN offset 13 12 11 10 9 8 7 6 5 4 3 2 1 0 Page Directory Index Once we extract the page-directory index (PDIndex for short) from the VPN, we can use it to find the address of the page-directory entry (PDE)withasimplecalculation: PDEAddr = PageDirBase + (PDIndex * sizeof(PDE)). This results in our page directory, which we now examine to make further progress in our translation. If the page-directory entry is marked invalid, we know that the access is invalid, and thus raise an exception. If, however, the PDE is valid, we have more work to do. Specifically, we now have to fetch the pagetable entry (PTE) from the page of the page table pointed to by this pagedirectory entry. To find this PTE, we have to index into the portion of the page table using the remaining bits of the VPN: OPERATING SYSTEMS WWW.OSTEP.ORG [VERSION 1.10]PAGING:SMALLERTABLES 9 13 12 11 10 9 8 7 6 5 4 3 2 1 0 VPN offset Page Directory Index Page Table Index Thispage-tableindex(PTIndexforshort)canthenbeusedtoindex intothepagetableitself,givingustheaddressofourPTE: PTEAddr= (PDE.PFN<<SHIFT)+ (PTIndex * sizeof(PTE)) Notethat thepage-framenumberobtainedfromthepage-directory entrymustbeleft-shiftedintoplacebeforecombiningitwiththepagetableindextoformtheaddressofthePTE. Toseeif thisallmakessense,we’llnowfill inamulti-levelpagetablewithsomeactualvalues,andtranslateasinglevirtualaddress.Let’s beginwiththepagedirectoryforthisexample(leftsideofFigure20.5). Inthefigure, youcanseethateachpagedirectoryentry(PDE)describessomethingaboutapageofthepagetablefortheaddressspace. Inthisexample,wehavetwovalidregionsintheaddressspace(atthe beginningandend),andanumberofinvalidmappingsin-between. Inphysicalpage100(thephysicalframenumberofthe0thpageofthe pagetable),wehavethefirstpageof16pagetableentriesforthefirst16 VPNsintheaddressspace.SeeFigure20.5(middlepart)forthecontents ofthisportionofthepagetable. Thispageof thepage tablecontains themappings for thefirst 16 VPNs; inourexample,VPNs0and1arevalid(thecodesegment), as PageDirectory PageofPT(@PFN:100) PageofPT(@PFN:101) PFN valid? PFN valid prot PFN valid prot 100 1 10 1 r-x — 0 — — 0 23 1 r-x — 0 — — 0 — 0 — — 0 — — 0 — 0 — — 0 — — 0 80 1 rw- — 0 — — 0 59 1 rw- — 0 — — 0 — 0 — — 0 — — 0 — 0 — — 0 — — 0 — 0 — — 0 — — 0 — 0 — — 0 — — 0 — 0 — — 0 — — 0 — 0 — — 0 — — 0 — 0 — — 0 — — 0 — 0 — — 0 — — 0 — 0 — 55 1 rw101 1 — 0 — 45 1 rwFigure20.5:APageDirectory,AndPiecesOfPageTable ©2008–23,ARPACI-DUSSEAU THREE EASY PIECES10 PAGING:SMALLERTABLES TIP:BEWARYOFCOMPLEXITY Systemdesignersshouldbewaryofaddingcomplexityintotheirsystem.Whatagoodsystemsbuilderdoesisimplementtheleastcomplex systemthatachievesthetaskathand.Forexample,ifdiskspaceisabundant,youshouldn’tdesignafilesystemthatworkshardtouseasfew bytesaspossible; similarly, ifprocessorsarefast, it isbetter towritea cleanandunderstandablemodulewithintheOSthanperhapsthemost CPU-optimized,hand-assembledcodeforthetaskathand. Bewaryof needlesscomplexity,inprematurely-optimizedcodeorotherforms;such approachesmakesystemsharder tounderstand,maintain, anddebug. AsAntoinedeSaint-Exuperyfamouslywrote: “Perfectionisfinallyattainednotwhenthereisnolongeranythingtoadd,butwhenthereisno longeranythingtotakeaway.”Whathedidn’twrite:“It’saloteasierto saysomethingaboutperfectionthantoactuallyachieveit.” are4and5(theheap).Thus,thetablehasmappinginformationforeach ofthosepages.Therestoftheentriesaremarkedinvalid. TheothervalidpageofthepagetableisfoundinsidePFN101. This pagecontainsmappingsforthelast16VPNsof theaddressspace; see Figure20.5(right)fordetails. Intheexample,VPNs254and255(thestack)havevalidmappings. Hopefully,whatwecanseefromthisexampleishowmuchspacesavings arepossiblewithamulti-levelindexedstructure. Inthisexample,instead ofallocatingthefullsixteenpagesforalinearpagetable,weallocateonly three:oneforthepagedirectory,andtwoforthechunksofthepagetable thathavevalidmappings.Thesavingsforlarge(32-bitor64-bit)address spacescouldobviouslybemuchgreater. Finally, let’suse this informationinorder toperformatranslation. Hereisanaddressthat referstothe0thbyteofVPN254: 0x3F80,or 11111110000000inbinary. Recall thatwewillusethetop4bitsof theVPNtoindexintothe pagedirectory. Thus,1111willchoosethelast(15th, ifyoustartatthe 0th)entryof thepagedirectoryabove. Thispointsus toavalidpage of thepagetable locatedataddress101. Wethenusethenext4bits of theVPN(1110) toindexintothatpageof thepagetableandfind thedesiredPTE. 1110 is thenext-to-last (14th)entryonthepage, and tellsusthatpage254ofourvirtualaddressspaceismappedatphysicalpage55.ByconcatenatingPFN=55(orhex0x37)withoffset=000000, wecanthusformourdesiredphysicaladdressandissuetherequestto thememorysystem:PhysAddr=(PTE.PFN<< SHIFT)+offset =00 110111000000=0x0DC0. Youshouldnowhavesomeideaofhowtoconstructatwo-levelpage table,usingapagedirectorywhichpointstopagesofthepagetable.Unfortunately,however,ourworkisnotdone.Aswe’llnowdiscuss,sometimestwolevelsofpagetableisnotenough! OPERATING SYSTEMS [VERSION1.10] WWW.OSTEP.ORGPAGING: SMALLER TABLES 11 More ThanTwoLevels In our example thus far, we’ve assumed that multi-level page tables only have two levels: a page directory and then pieces of the page table. In some cases, a deeper tree is possible (and indeed, needed). Let’s take a simple example and use it to show why a deeper multilevel table can be useful. In this example, assume we have a 30-bit virtual address space, and a small (512 byte) page. Thus our virtual address has a 21-bit virtual page number component and a 9-bit offset. Remember our goal in constructing a multi-level page table: to make each piece of the page table fit within a single page. Thus far, we’ve only considered the page table itself; however, what if the page directory gets too big? To determine how many levels are needed in a multi-level table to makeallpiecesofthepagetablefitwithinapage,westartbydetermining howmanypage-tableentries fit within a page. Givenourpagesizeof512 bytes, and assuming a PTE size of 4 bytes, you should see that you can fit 128 PTEs on a single page. When we index into a page of the page table, we can thus conclude we’ll need the least significant 7 bits (log2128) of the VPNas anindex: VPN offset 292827 262524 232221 201918 171615 141312 1110 9 8 7 6 5 4 3 2 1 0 Page Directory Index Page Table Index What youalso might notice from the diagram above is how many bits are left into the (large) page directory: 14. If our page directory has 214 entries (and 4-byte PDEs), it spans not one page but 128, and our goal of making every piece of the multi-level page table fit into a page vanishes. To remedy this problem, we build a further level of the tree, by splitting the pagedirectoryitself into multiplepages, andthenaddinganother page directory on top of that, to point to the pages of the page directory. Wecanthus split up our virtual address as follows: VPN offset 292827 262524 232221 201918 171615 141312 1110 9 8 7 6 5 4 3 2 1 0 PD Index 0 PD Index 1 Page Table Index Now, when indexing the upper-level page directory, we use the very top bits of the virtual address (PD Index 0 in the diagram); this index can be used to fetch the page-directory entry from the top-level page directory. If valid, the second level of the page directory is consulted by combining the physical frame number from the top-level PDE and the ©2008–23, ARPACI-DUSSEAU THREE EASY PIECES12 PAGING: SMALLER TABLES 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 VPN = (VirtualAddress & VPN_MASK) >> SHIFT (Success, TlbEntry) = TLB_Lookup(VPN) if (Success == True) // TLB Hit if (CanAccess(TlbEntry.ProtectBits) == True) Offset = VirtualAddress & OFFSET_MASK PhysAddr = (TlbEntry.PFN << SHIFT) | Offset Register = AccessMemory(PhysAddr) else RaiseException(PROTECTION_FAULT) else // TLB Miss // first, get page directory entry PDIndex = (VPN & PD_MASK) >> PD_SHIFT PDEAddr = PDBR + (PDIndex * sizeof(PDE)) PDE = AccessMemory(PDEAddr) if (PDE.Valid == False) RaiseException(SEGMENTATION_FAULT) else // PDE is valid: now fetch PTE from page table PTIndex = (VPN & PT_MASK) >> PT_SHIFT PTEAddr = (PDE.PFN<<SHIFT) + (PTIndex*sizeof(PTE)) PTE = AccessMemory(PTEAddr) if (PTE.Valid == False) RaiseException(SEGMENTATION_FAULT) else if (CanAccess(PTE.ProtectBits) == False) RaiseException(PROTECTION_FAULT) else TLB_Insert(VPN, PTE.PFN, PTE.ProtectBits) RetryInstruction() Figure 20.6: Multi-level Page Table Control Flow next part of the VPN (PD Index 1). Finally, if valid, the PTE address can be formed by using the page-table index combined with the address from the second-level PDE. Whew! That’s a lot of work. And all just to look something up in a multi-level table. The Translation Process: Remember the TLB To summarize the entire process of address translation using a two-level page table, we once again present the control flow in algorithmic form (Figure 20.6). The figure shows what happens in hardware (assuming a hardware-managed TLB) upon every memory reference. As you can see from the figure, before any of the complicated multilevel page table access occurs, the hardware first checks the TLB; upon a hit, the physical address is formed directly without accessing the page table at all, as before. Only upon a TLB miss does the hardware need to perform the full multi-level lookup. On this path, you can see the cost of our traditional two-level page table: two additional memory accesses to look up a valid translation. OPERATING SYSTEMS WWW.OSTEP.ORG [VERSION 1.10]PAGING: SMALLER TABLES 13 20.4 Inverted Page Tables An even more extreme space savings in the world of page tables is found with inverted page tables. Here, instead of having many page tables (one per process of the system), we keep a single page table that has an entry for each physical page of the system. The entry tells us which process is using this page, and which virtual page of that process maps to this physical page. Finding the correct entry is now a matter of searching through this data structure. A linear scan would be expensive, and thus a hash table is often built over the base structure to speed up lookups. The PowerPC is one example of such an architecture [JM98]. More generally, inverted page tables illustrate what we’ve said from the beginning: page tables are just data structures. You can do lots of crazy things with data structures, making them smaller or bigger, making them slower or faster. Multi-level and inverted page tables are just two examples of the many things one could do. 20.5 Swapping the Page Tables to Disk Finally, we discuss the relaxation of one final assumption. Thus far, wehaveassumedthat page tables reside in kernel-owned physical memory. Even with our many tricks to reduce the size of page tables, it is still possible, however, that they may be too big to fit into memory all at once. Thus, some systems place such page tables in kernel virtual memory, thereby allowing the system to swap some of these page tables to disk when memory pressure gets a little tight. We’ll talk more about this in a future chapter (namely, the case study on VAX/VMS), once we understand how to move pages in and out of memory in more detail. 20.6 Summary We have now seen how real page tables are built; not necessarily just as linear arrays but as more complex data structures. The trade-offs such tables present are in time and space — the bigger the table, the faster a TLB miss can be serviced, as well as the converse — and thus the right choice of structure depends strongly on the constraints of the given environment. In amemory-constrainedsystem(likemanyoldersystems),smallstructures make sense; in a system with a reasonable amount of memory and with workloads that actively use a large number of pages, a bigger table that speeds up TLB misses might be the right choice. With softwaremanagedTLBs,theentire space of data structures opens up to the delight of the operating system innovator (hint: that’s you). What new structures can you come up with? What problems do they solve? Think of these questions as you fall asleep, and dream the big dreams that only operating-system developers can dream.