21 Beyond Physical Memory: Mechanisms Thus far, we’ve assumed that an address space is unrealistically small and fits into physical memory. In fact, we’ve been assuming that every address space of every running process fits into memory. We will now relax these big assumptions, and assume that we wish to support many concurrently-running large address spaces. To do so, we require an additional level in the memory hierarchy. Thus far, we have assumed that all pages reside in physical memory. However, to support large address spaces, the OS will need a place to stash away portions of address spaces that currently aren’t in great demand. In general, the characteristics of such a location are that it should have more capacity than memory; as a result, it is generally slower (if it were faster, we would just use it as memory, no?). In modern systems, this role is usually served by a hard disk drive. Thus, in our memory hierarchy, big and slow hard drives sit at the bottom, with memory just above. And thus we arrive at the crux of the problem: THE CRUX: HOW TO GO BEYOND PHYSICAL MEMORY HowcantheOSmakeuseofalarger, slower device to transparently provide the illusion of a large virtual address space? One question you might have: why do we want to support a single large address space for a process? Once again, the answer is convenience and ease of use. With a large address space, you don’t have to worry about if there is enough room in memory for your program’s data structures; rather, you just write the program naturally, allocating memory as needed. It is a powerful illusion that the OS provides, and makes your life vastly simpler. You’re welcome! A contrast is found in older systems that used memory overlays, which required programmers to manually move pieces of code or data in and out of memory as they were needed [D97]. Try imagining what this would be like: before calling a function or accessing some data, you need to first arrange for the code or data to be in memory; yuck! 12 BEYOND PHYSICAL MEMORY: MECHANISMS ASIDE: STORAGE TECHNOLOGIES We’ll delve much more deeply into how I/O devices actually work later (see the chapter on I/O devices). So be patient! And of course the slower device need not be a hard disk, but could be something more modern such as a Flash-based SSD. We’ll talk about those things too. For now, just assume we have a big and relatively-slow device which we can use to help us build the illusion of a very large virtual memory, even bigger than physical memory itself. Beyond just a single process, the addition of swap space allows the OS to supporttheillusionofalargevirtualmemoryformultipleconcurrentlyrunning processes. The invention of multiprogramming (running multiple programs “at once”, to better utilize the machine) almost demanded the ability to swap out some pages, as early machines clearly could not hold all the pages needed by all processes at once. Thus, the combination of multiprogramming and ease-of-use leads us to want to support using more memory than is physically available. It is something that all modern VMsystems do; it is now something we will learn more about. 21.1 Swap Space The first thing we will need to do is to reserve some space on the disk for movingpagesbackandforth. Inoperatingsystems,wegenerallyrefer to such space as swap space, because we swap pages out of memory to it and swap pages into memory from it. Thus, we will simply assume that the OScanreadfromandwritetothe swapspace, in page-sized units. To do so, the OS will need to remember the disk address of a given page. The size of the swap space is important, as ultimately it determines the maximumnumberofmemorypagesthatcanbeinusebyasystemat a given time. Let us assume for simplicity that it is very large for now. In the tiny example (Figure 21.1), you can see a little example of a 4page physical memory and an 8-page swap space. In the example, three processes (Proc 0, Proc 1, and Proc 2) are actively sharing physical memory; each of the three, however, only have some of their valid pages in memory, with the rest located in swap space on disk. A fourth process (Proc 3) has all of its pages swapped out to disk, and thus clearly isn’t currently running. One block of swap remains free. Even from this tiny example, hopefully you can see how using swap space allows the system to pretend that memory is larger than it actually is. We should note that swap space is not the only on-disk location for swappingtraffic. For example, assumeyouarerunningaprogrambinary (e.g., ls, or your owncompiledmainprogram). Thecodepagesfromthis binary are initially found on disk, and when the program runs, they are loadedintomemory(eitherallatoncewhentheprogramstartsexecution, OPERATING SYSTEMS WWW.OSTEP.ORG [VERSION 1.10]BEYOND PHYSICAL MEMORY: MECHANISMS 3 Physical Memory Swap Space PFN 0 Proc 0 [VPN 0] PFN 1 Proc 1 [VPN 2] PFN 2 Proc 1 [VPN 3] PFN 3 Proc 2 [VPN 0] Block 0 Proc 0 [VPN 1] Block 1 Proc 0 [VPN 2] Block 2 Block 3 Proc 1 Block 4 Proc 1 [Free] [VPN 0] [VPN 1] Block 5 Proc 3 [VPN 0] Block 6 Proc 2 [VPN 1] Block 7 Proc 3 [VPN 1] Figure 21.1: Physical Memory and Swap Space or, as in modern systems, one page at a time when needed). However, if the system needs to make room in physical memory for other needs, it can safely re-use the memory space for these code pages, knowing that it can later swap them in again from the on-disk binary in the file system. 21.2 The Present Bit Nowthat we have some space on the disk, we need to add some machinery higher up in the system in order to support swapping pages to and from the disk. Let us assume, for simplicity, that we have a system with a hardware-managed TLB. Recall first what happens on a memory reference. The running process generates virtual memory references (for instruction fetches, or data accesses), and, in this case, the hardware translates them into physical addresses before fetching the desired data from memory. Remember that the hardware first extracts the VPN from the virtual address, checks the TLB for a match (a TLB hit), and if a hit, produces the resulting physical address and fetches it from memory. This is hopefully the common case, as it is fast (requiring no additional memory accesses). If the VPN is not found in the TLB (i.e., a TLB miss), the hardware locates the page table in memory (using the page table base register) and looks up the page table entry (PTE) for this page using the VPN as an index. If the page is valid and present in physical memory, the hardware extracts the PFN from the PTE, installs it in the TLB, and retries the instruction, this time generating a TLB hit; so far, so good. If we wish to allow pages to be swapped to disk, however, we must add even more machinery. Specifically, when the hardware looks in the PTE, it may find that the page is not present in physical memory. The way the hardware (or the OS, in a software-managed TLB approach) determines this is through a new piece of information in each page-table entry, known as the present bit. If the present bit is set to one, it means the page is present in physical memory and everything proceeds as above; if it is set to zero, the page is not in memory but rather on disk somewhere. ©2008–23, ARPACI-DUSSEAU THREE EASY PIECES4 BEYOND PHYSICAL MEMORY: MECHANISMS ASIDE: SWAPPING TERMINOLOGY AND OTHER THINGS Terminologyinvirtualmemorysystemscanbealittleconfusingandvariable across machines and operating systems. For example, a page fault more generally could refer to any reference to a page table that generates a fault of somekind: this could include the type of fault we are discussing here, i.e., a page-not-present fault, but sometimes canrefertoillegal memory accesses. Indeed, it is odd that we call what is definitely a legal access (to a page mapped into the virtual address space of a process, but simply not in physical memory at the time) a “fault” at all; really, it should be called a page miss. But often, when people say a program is “page faulting”, they mean that it is accessing parts of its virtual address space that the OS has swapped out to disk. We suspect the reason that this behavior became known as a “fault” relates to the machinery in the operating system to handle it. When something unusual happens, i.e., when something the hardware doesn’t know how to handle occurs, the hardware simply transfers control to the OS, hoping it can make things better. In this case, a page that a process wants to access is missing from memory; the hardware does the only thing it can, which is raise an exception, and the OS takes over from there. As this is identical to what happens when a process does something illegal, it is perhaps not surprising that we term the activity a “fault.” The act of accessing a page that is not in physical memory is commonly referred to as a page fault. Uponapagefault,theOSisinvokedtoservicethepagefault. Aparticular piece of code, knownasapage-faulthandler, runs, and mustservice the page fault, as we now describe. 21.3 The Page Fault Recall that with TLB misses, we have two types of systems: hardwaremanaged TLBs (where the hardware looks in the page table to find the desired translation) and software-managed TLBs (where the OS does). In either type of system, if a page is not present, the OS is put in charge to handle the page fault. The appropriately-named OS page-fault handler runs to determine what to do. Virtually all systems handle page faults in software; even with a hardware-managed TLB, the hardware trusts the OSto manage this important duty. If a pageis notpresent andhasbeenswappedtodisk,theOSwillneed to swap the page into memory in order to service the page fault. Thus, a question arises: how will the OS know where to find the desired page? In manysystems, the page table is a natural place to store such information. Thus, the OS could use the bits in the PTE normally used for data such as the PFNofthepageforadiskaddress. WhentheOSreceives apagefault OPERATING SYSTEMS WWW.OSTEP.ORG [VERSION 1.10]BEYONDPHYSICALMEMORY:MECHANISMS 5 ASIDE:WHYHARDWAREDOESN’THANDLEPAGEFAULTS WeknowfromourexperiencewiththeTLBthathardwaredesignersare loathtotrusttheOStodomuchofanything.SowhydotheytrusttheOS tohandleapagefault?Thereareafewmainreasons. First,pagefaults todiskareslow;eveniftheOStakesalongtimetohandleafault,executingtonsof instructions, thediskoperationitself istraditionallysoslow thattheextraoverheadsofrunningsoftwareareminimal. Second, tobe abletohandleapagefault,thehardwarewouldhavetounderstandswap space,howtoissueI/Ostothedisk,andalotofotherdetailswhichitcurrentlydoesn’tknowmuchabout.Thus,forbothreasonsofperformance andsimplicity,theOShandlespagefaults,andevenhardwaretypescan behappy. forapage, itlooksinthePTEtofindtheaddress,andissuestherequest todisktofetchthepageintomemory. WhenthediskI/Ocompletes,theOSwillthenupdatethepagetable tomarkthepageaspresent,updatethePFNfieldofthepage-tableentry (PTE) torecordthein-memorylocationof thenewly-fetchedpage,and retrytheinstruction.ThisnextattemptmaygenerateaTLBmiss,which wouldthenbeservicedandupdatetheTLBwiththetranslation(one couldalternatelyupdatetheTLBwhenservicingthepagefaulttoavoid thisstep).Finally,alastrestartwouldfindthetranslationintheTLBand thusproceedtofetchthedesireddataorinstructionfrommemoryatthe translatedphysicaladdress. NotethatwhiletheI/Oisinflight,theprocesswillbeintheblocked state. Thus, theOSwillbefreetorunotherreadyprocesseswhilethe pagefault isbeingserviced. BecauseI/Oisexpensive, thisoverlapof theI/O(pagefault)ofoneprocessandtheexecutionofanother isyet anotherwayamultiprogrammedsystemcanmakethemosteffectiveuse ofitshardware. 21.4WhatIfMemoryIsFull? Intheprocessdescribedabove,youmaynoticethatweassumedthere isplentyof freememoryinwhichtopageinapagefromswapspace. Ofcourse, thismaynotbethecase;memorymaybefull(orclosetoit). Thus,theOSmightliketofirstpageoutoneormorepagestomakeroom forthenewpage(s)theOSisabouttobringin.Theprocessofpickinga pagetokickout,orreplaceisknownasthepage-replacementpolicy. Asitturnsout,alotofthoughthasbeenputintocreatingagoodpagereplacementpolicy,askickingoutthewrongpagecanexactagreatcost onprogramperformance.Makingthewrongdecisioncancauseaprogramtorunatdisk-likespeedsinsteadofmemory-likespeeds; incurrenttechnologythatmeansaprogramcouldrun10,000or100,000times ©2008–23,ARPACI-DUSSEAU THREE EASY PIECES6 BEYOND PHYSICAL MEMORY: MECHANISMS 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 VPN = (VirtualAddress & VPN_MASK) >> SHIFT (Success, TlbEntry) = TLB_Lookup(VPN) if (Success == True) // TLB Hit if (CanAccess(TlbEntry.ProtectBits) == True) Offset = VirtualAddress & OFFSET_MASK PhysAddr = (TlbEntry.PFN << SHIFT) | Offset Register = AccessMemory(PhysAddr) else RaiseException(PROTECTION_FAULT) else // TLB Miss PTEAddr = PTBR + (VPN * sizeof(PTE)) PTE = AccessMemory(PTEAddr) if (PTE.Valid == False) RaiseException(SEGMENTATION_FAULT) else if (CanAccess(PTE.ProtectBits) == False) RaiseException(PROTECTION_FAULT) else if (PTE.Present == True) // assuming hardware-managed TLB TLB_Insert(VPN, PTE.PFN, PTE.ProtectBits) RetryInstruction() else if (PTE.Present == False) RaiseException(PAGE_FAULT) Figure 21.2: Page-Fault Control Flow Algorithm (Hardware) slower. Thus, such a policy is something we should study in some detail; indeed, that is exactly what we will do in the next chapter. For now, it is good enough to understand that such a policy exists, built on top of the mechanisms described here. 21.5 Page Fault Control Flow With all of this knowledge in place, we can now roughly sketch the complete control flow of memory access. In other words, when somebody asks you “what happens when a program fetches some data from memory?”, you should have a pretty good idea of all the different possibilities. See the control flow in Figures 21.2 and 21.3 for more details; the first figure shows what the hardware does during translation, and the second what the OS does upon a page fault. From the hardware control flow diagram in Figure 21.2, notice that there are now three important cases to understand when a TLB miss occurs. First, that the page was both present and valid (Lines 18–21); in this case, the TLB miss handler can simply grab the PFN from the PTE, retry the instruction (this time resulting in a TLB hit), and thus continue as described (many times) before. In the second case (Lines 22–23), the page fault handler must be run; although this was a legitimate page for OPERATING SYSTEMS WWW.OSTEP.ORG [VERSION 1.10]BEYOND PHYSICAL MEMORY: MECHANISMS 7 1 2 3 4 5 6 7 PFN = FindFreePhysicalPage() if (PFN ==-1) // no free page found PFN = EvictPage() // replacement algorithm DiskRead(PTE.DiskAddr, PFN) // sleep (wait for I/O) PTE.present = True // update page table: PTE.PFN = PFN RetryInstruction() // (present/translation) // retry instruction Figure 21.3: Page-Fault Control Flow Algorithm (Software) the process to access (it is valid, after all), it is not present in physical memory. Third (and finally), the access could be to an invalid page, due for example to a bug in the program (Lines 13–14). In this case, no other bits in the PTE really matter; the hardware traps this invalid access, and the OS trap handler runs, likely terminating the offending process. From the software control flow in Figure 21.3, we can see what the OS roughly must doinordertoservice the page fault. First, the OS must find a physical frame for the soon-to-be-faulted-in page to reside within; if there is no such page, we’ll have to wait for the replacement algorithm to run and kick some pages out of memory, thus freeing them for use here. With a physical frame in hand, the handler then issues the I/O request to read in the page from swap space. Finally, when that slow operation completes, the OS updates the page table and retries the instruction. The retry will result in a TLB miss, and then, upon another retry, a TLB hit, at which point the hardware will be able to access the desired item. 21.6 When Replacements Really Occur Thus far, the way we’ve described how replacements occur assumes that the OS waits until memory is entirely full, and only then replaces (evicts) a page to make room for some other page. As you can imagine, this is a little bit unrealistic, and there are many reasons for the OS to keep a small portion of memory free more proactively. To keep a small amount of memory free, most operating systems thus have some kind of high watermark (HW) and low watermark (LW) to help decidewhentostartevictingpagesfrommemory. Howthisworksis as follows: whentheOSnoticesthattherearefewerthanLW pagesavailable, a background thread that is responsible for freeing memory runs. The thread evicts pages until there are HW pages available. The background thread, sometimes called the swap daemon or page daemon1, then goes to sleep, happy that it has freed some memory for running processes and the OS to use. By performing a number of replacements at once, new performance optimizations become possible. For example, many systems will cluster 1The word “daemon”, usually pronounced “demon”, is an old term for a background thread or process that does something useful. Turns out (once again!) that the source of the term is Multics [CS94]. ©2008–23, ARPACI-DUSSEAU THREE EASY PIECES8 BEYONDPHYSICALMEMORY:MECHANISMS TIP:DOWORKINTHEBACKGROUND Whenyouhavesomeworktodo, it isoftenagoodideatodoit inthe backgroundtoincreaseefficiencyandtoallowforgroupingofoperations.Operatingsystemsoftendoworkinthebackground;forexample, manysystemsbufferfilewrites inmemorybeforeactuallywritingthe datatodisk. Doingsohasmanypossiblebenefits: increaseddiskefficiency,asthediskmaynowreceivemanywritesatonceandthusbetter beabletoschedulethem; improvedlatencyofwrites,astheapplication thinksthewritescompletedquitequickly;thepossibilityofworkreduction,asthewritesmayneednevertogotodisk(i.e.,ifthefileisdeleted); andbetteruseof idletime, as thebackgroundworkmaypossiblybe donewhenthesystemisotherwiseidle, thusbetterutilizingthehardware[G+95]. orgroupanumberofpagesandwritethemoutatoncetotheswappartition,thusincreasingtheefficiencyofthedisk[LL82];aswewillseelater whenwediscussdisksinmoredetail,suchclusteringreducesseekand rotationaloverheadsofadiskandthusincreasesperformancenoticeably. Toworkwiththebackgroundpagingthread,thecontrolflowinFigure 21.3shouldbemodifiedslightly; insteadofperformingareplacement directly, thealgorithmwouldinsteadsimplycheckif thereareanyfree pagesavailable. Ifnot, itwouldinformthebackgroundpagingthread thatfreepagesareneeded;whenthethreadfreesupsomepages,itwould re-awakentheoriginalthread,whichcouldthenpageinthedesiredpage andgoaboutitswork. 21.7Summary Inthisbriefchapter,wehaveintroducedthenotionofaccessingmore memorythanisphysicallypresentwithinasystem. Todosorequires morecomplexityinpage-tablestructures,asapresentbit(ofsomekind) mustbeincludedtotelluswhetherthepageispresentinmemoryornot. Whennot, theoperatingsystempage-faulthandlerrunstoservicethe pagefault,andthusarrangesforthetransferof thedesiredpagefrom disktomemory,perhapsfirstreplacingsomepagesinmemorytomake roomforthosesoontobeswappedin. Recall, importantly(andamazingly!), thattheseactionsalltakeplace transparentlytotheprocess.Asfarastheprocessisconcerned, itisjust accessingitsownprivate,contiguousvirtualmemory.Behindthescenes, pagesareplacedinarbitrary(non-contiguous)locationsinphysicalmemory,andsometimestheyarenotevenpresentinmemory,requiringafetch fromdisk.Whilewehopethat inthecommoncaseamemoryaccessis fast,insomecasesitwilltakemultiplediskoperationstoserviceit;somethingassimpleasperformingasingleinstructioncan, intheworstcase, takemanymillisecondstocomplete.